需求：统计主站每个(指定)课程访问的客户端、地域信息分布
	地域：ip转换   Spark SQL项目实战
	客户端：useragent获取  Hadoop基础课程
	==> 如上两个操作：采用离线(Spark/MapReduce)的方式进行统计


实现步骤：
	课程编号、ip信息、useragent
	进行相应的统计分析操作：MapReduce/Spark

项目架构
	日志收集：Flume
	离线分析：MapReduce/Spark
	统计结果图形化展示

问题
	小时级别
	10分钟
	5分钟
	1分钟
	秒级别

如何解决？？？ ==》 实时流处理框架


离线计算与实时计算的对比
1) 数据来源
	离线： HDFS 历史数据  数据量比较大
	实时： 消息队列(Kafka)，实时新增/修改记录过来的某一笔数据

2）处理过程
	离线： MapReduce： map + reduce
	实时： Spark(DStream/SS)  

3) 处理速度
	离线： 慢
	实时： 快速

4）进程
	离线： 启动+销毁
	实时： 7*24



































